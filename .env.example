# ============================================================================
# Healthcare RAG Assistant - Environment Configuration Template
# ============================================================================
# Copy this file to .env and fill in your actual values
# 
# Usage:
#   cp .env.example .env
#   # Then edit .env with your actual values
# ============================================================================

# ============================================================================
# REQUIRED SETTINGS
# ============================================================================

# API Keys for authentication (comma-separated list)
# Generate secure keys using: python3 -c "import secrets; print(secrets.token_urlsafe(32))"
# Or use the helper script: python3 generate_api_key.py --save
# Example: API_KEYS=key1,key2,key3
# For development, you can use simple keys like: API_KEYS=dev-key-12345
API_KEYS=your-api-key-here,another-key-if-needed

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================

# Environment: development, production, or testing
ENV=development

# Server host and port
HOST=0.0.0.0
PORT=8000

# CORS origins (comma-separated URLs allowed to access the API)
# Examples:
#   - Single origin: CORS_ORIGINS=http://localhost:3000
#   - Multiple origins: CORS_ORIGINS=http://localhost:3000,https://example.com
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Use DEBUG for development, INFO or WARNING for production
LOG_LEVEL=INFO

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================

# Embedding model for text vectorization
# Default: paraphrase-multilingual-MiniLM-L12-v2 (supports English and Japanese)
# Other options:
#   - all-MiniLM-L6-v2 (smaller, English only)
#   - multilingual-e5-base (better multilingual support)
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2

# Embedding dimension (must match your chosen model)
# Common values: 128, 256, 384, 512, 768, 1024
# For paraphrase-multilingual-MiniLM-L12-v2: 384
EMBEDDING_DIM=384

# Translation models (Helsinki-NLP MarianMT models)
# English to Japanese translation
TRANSLATION_MODEL_EN_JA=Helsinki-NLP/opus-mt-en-ja

# Japanese to English translation
TRANSLATION_MODEL_JA_EN=Helsinki-NLP/opus-mt-ja-en

# ============================================================================
# FAISS VECTOR STORE CONFIGURATION
# ============================================================================

# Directory where FAISS index files will be stored
# The directory will be created automatically if it doesn't exist
FAISS_INDEX_DIR=data/faiss_index

# ============================================================================
# FILE UPLOAD CONFIGURATION
# ============================================================================

# Maximum file size for document uploads (in megabytes)
# Range: 1-100 MB
MAX_FILE_SIZE_MB=10

# Target chunk size for text splitting (in characters)
# Range: 100-2000 characters
# Smaller chunks = more precise retrieval but more chunks to store
# Larger chunks = less storage but may include irrelevant content
MAX_CHUNK_SIZE=500

# Number of sentences to overlap between chunks
# Range: 0-5
# Overlap helps maintain context between chunks
MAX_CHUNK_OVERLAP=1

# Allowed file extensions for uploads (comma-separated)
# Currently only .txt files are supported
ALLOWED_EXTENSIONS=.txt

# ============================================================================
# RATE LIMITING
# ============================================================================
# Rate limits for API endpoints (format: "number/period")
# Examples: "10/hour", "100/minute", "1000/day"
# Set to "0/hour" to disable rate limiting for an endpoint

# Rate limit for document ingestion endpoint
# Lower limit recommended since ingestion is resource-intensive
RATE_LIMIT_INGEST=10/hour

# Rate limit for document retrieval endpoint
# Can be higher since retrieval is faster
RATE_LIMIT_RETRIEVE=100/hour

# Rate limit for response generation endpoint
# Moderate limit since generation involves LLM processing
RATE_LIMIT_GENERATE=50/hour

# ============================================================================
# OPTIONAL ADVANCED SETTINGS
# ============================================================================
# The following settings are not in config.py but can be added:
#
# GENERATION_TOP_K=5              # Number of documents to retrieve for generation
# GENERATION_MIN_SCORE=0.3        # Minimum similarity score for retrieval
# GENERATION_TIMEOUT=30           # Timeout for generation requests (seconds)
# INGEST_TIMEOUT=60               # Timeout for ingestion requests (seconds)
